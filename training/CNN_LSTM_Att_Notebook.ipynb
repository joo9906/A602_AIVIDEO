{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 수어 인식 모델 - CNN + LSTM + Attention\n",
        "\n",
        "이 노트북은 수어 인식을 위한 CNN + LSTM 하이브리드 모델을 구현합니다.\n",
        "\n",
        "## 주요 특징\n",
        "- 버킷 기반 시퀀스 길이 정규화\n",
        "- 에러 처리 및 검증\n",
        "- GPU 최적화\n",
        "- 실시간 예측 지원\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 라이브러리 및 초기 설정\n",
        "\n",
        "- pip은 GPU 서버에서 돌리기에는 충돌(tensor 충돌 때문에 GPU를 탐지하지를 못함)때문에 사용하지 않음. 로컬에서는 괜찮음\n",
        "- 재현성을 위해 np tf의 시드를 42로 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 버전: 2.14.0\n",
            "GPU 사용 가능: []\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from config import ModelConfig as cf\n",
        "\n",
        "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
        "print(f\"GPU 사용 가능: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 시퀀스 길이 정규화 클래스\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본: (15, 225) → 정규화: (60, 225)\n"
          ]
        }
      ],
      "source": [
        "class NormalizeSequenceLength:\n",
        "    \"\"\"\n",
        "    시퀀스 길이를 정규화하는 클래스\n",
        "    - 패딩: 짧은 시퀀스를 0으로 채움\n",
        "    - 트리밍: 긴 시퀀스를 균등 샘플링\n",
        "    \"\"\"\n",
        "    \n",
        "    def pad_or_trim(self, seq: np.ndarray, target_len: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        시퀀스를 target_len 길이로 정규화\n",
        "        \n",
        "        Args:\n",
        "            seq: 입력 시퀀스 (2D array)\n",
        "            target_len: 목표 길이\n",
        "            \n",
        "        Returns:\n",
        "            정규화된 시퀀스\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 입력 검증\n",
        "            if seq is None or seq.size == 0:\n",
        "                raise ValueError(\"입력 시퀀스가 비어있습니다.\")\n",
        "            \n",
        "            if len(seq.shape) != 2:\n",
        "                raise ValueError(f\"시퀀스는 2차원 배열이어야 합니다. 현재 shape: {seq.shape}\")\n",
        "            \n",
        "            t, F = seq.shape\n",
        "            \n",
        "            if target_len <= 0:\n",
        "                raise ValueError(f\"target_len은 양수여야 합니다. 현재 값: {target_len}\")\n",
        "            \n",
        "            # 길이가 같으면 그대로 반환\n",
        "            if t == target_len:\n",
        "                return seq\n",
        "            \n",
        "            # 길이가 길면 샘플링\n",
        "            if t > target_len:\n",
        "                idx = np.linspace(0, t - 1, target_len).astype(int)\n",
        "                return seq[idx]\n",
        "            \n",
        "            # 길이가 짧으면 패딩\n",
        "            pad = np.zeros((target_len - t, F), dtype=seq.dtype)\n",
        "            return np.vstack([seq, pad])\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"pad_or_trim 에러: {e}\")\n",
        "            raise\n",
        "\n",
        "    def nearest_bucket_len(self, t: int, buckets=cf.BUCKETS) -> int:\n",
        "        \"\"\"\n",
        "        현재 길이와 가장 가까운 버킷 길이를 반환\n",
        "        \n",
        "        Args:\n",
        "            t: 현재 시퀀스 길이\n",
        "            buckets: 사용 가능한 버킷 길이들\n",
        "            \n",
        "        Returns:\n",
        "            가장 가까운 버킷 길이\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if t <= 0:\n",
        "                raise ValueError(f\"시퀀스 길이는 양수여야 합니다. 현재 값: {t}\")\n",
        "            \n",
        "            if not buckets or len(buckets) == 0:\n",
        "                raise ValueError(\"버킷 리스트가 비어있습니다.\")\n",
        "            \n",
        "            if any(b <= 0 for b in buckets):\n",
        "                raise ValueError(\"모든 버킷 값은 양수여야 합니다.\")\n",
        "            \n",
        "            return min(buckets, key=lambda b: abs(b - t))\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"nearest_bucket_len 에러: {e}\")\n",
        "            raise\n",
        "\n",
        "# 테스트\n",
        "normalizer = NormalizeSequenceLength()\n",
        "test_seq = np.random.rand(15, 225)  # 15프레임 시퀀스\n",
        "normalized = normalizer.pad_or_trim(test_seq, 60)\n",
        "print(f\"원본: {test_seq.shape} → 정규화: {normalized.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 수어 인식 모델 클래스\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SignLanguageModel:\n",
        "    \"\"\"\n",
        "    수어 인식을 위한 CNN + LSTM 하이브리드 모델\n",
        "    \n",
        "    특징:\n",
        "    - TimeDistributed CNN으로 프레임별 특징 추출\n",
        "    - LSTM으로 시계열 패턴 학습\n",
        "    - 버킷 기반 시퀀스 길이 정규화\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"모델 초기화\"\"\"\n",
        "        self.num_classes = cf.NUM_CLASSES\n",
        "        self.sequence_length = cf.SEQUENCE_LENGTH\n",
        "        self.feature_dim = cf.FEATURE_DIM\n",
        "        self.model = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.normalizer = NormalizeSequenceLength()\n",
        "        \n",
        "        print(f\"모델 설정:\")\n",
        "        print(f\"  - 시퀀스 길이: {self.sequence_length}\")\n",
        "        print(f\"  - 특성 차원: {self.feature_dim}\")\n",
        "        print(f\"  - 클래스 수: {self.num_classes}\")\n",
        "        print(f\"  - 버킷: {cf.BUCKETS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 모델 구성\n",
        "- CNN 3계층\n",
        "- BiLSTM\n",
        "- Attention\n",
        "- Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(self):\n",
        "    \"\"\"\n",
        "    CNN + LSTM 하이브리드 모델 구성\n",
        "    \n",
        "    구조:\n",
        "    1. TimeDistributed CNN (프레임별 특징 추출)\n",
        "    2. LSTM (시계열 패턴 학습)\n",
        "    3. Dense (분류)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 입력 검증\n",
        "        if self.sequence_length <= 0 or self.feature_dim <= 0:\n",
        "            raise ValueError(f\"잘못된 입력 크기: sequence_length={self.sequence_length}, feature_dim={self.feature_dim}\")\n",
        "        \n",
        "        print(\"모델 구성 중...\")\n",
        "        \n",
        "        # 입력층\n",
        "        inputs = keras.Input(shape=(self.sequence_length, self.feature_dim))\n",
        "        \n",
        "        # CNN을 위한 reshape    \n",
        "        # Conv1D(1차원 합성곱)은 입력을 길이(sequence_length), 채널(feature_dim)으로 받음\n",
        "        # 아래의 TimeDistributed를 사용하려면 프레임마다 (F,1)로 보이게 해야되므로 reshape 하는 것\n",
        "        x = layers.Reshape((self.sequence_length, self.feature_dim, 1))(inputs)\n",
        "        \n",
        "        # TimeDistributed CNN 블록 1\n",
        "        # 프레임 별로 Conv1D를 적용, 3은 인접 피처 3개를 한번에 포며 로컬 패턴을 잡는 다는 것\n",
        "        # BN으로 분포 안정화, MaxPooling으로 피처 길이를 반으로 잘라 요약, Dropout으로 과적합 완화\n",
        "        x = layers.TimeDistributed(layers.Conv1D(64, 3, activation='relu', padding='same'))(x)\n",
        "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "        x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
        "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "        # TimeDistributed CNN 블록 2\n",
        "        # 채널(128)을 늘려 풍부한 패턴으로 표현, Pool로 다시 절반으로 자름\n",
        "        x = layers.TimeDistributed(layers.Conv1D(128, 3, activation='relu', padding='same'))(x)\n",
        "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "        x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
        "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "        # TimeDistributed CNN 블록 3\n",
        "        # 256채널까지로 늘려 표현, GlobalMaxPooling1D를 사용해 프레임 내부 길이축(F/4)를 완전히 접어\n",
        "        # 프레임을 256차원 벡터로 축약\n",
        "        # 텐서는 시퀀스 * 프레임 벡터 형태가 되어 LSTM을 위한 입력이 됨.\n",
        "        x = layers.TimeDistributed(layers.Conv1D(256, 3, activation='relu', padding='same'))(x)\n",
        "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "        x = layers.TimeDistributed(layers.GlobalMaxPooling1D())(x)\n",
        "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "        # LSTM 블록\n",
        "        # 512와 256은 리턴 시퀀스가 T라는 것은 모든 타임스텝의 출력을 다음 LSTM으로 전달하겠다는 뜻.\n",
        "        # 그래서 128은 마지막 층이기에 리턴시퀀스가 없음, 대신 요약 벡터만 남겨 문맥 응축\n",
        "        x = layers.Bidirectional(layers.LSTM(512, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "        # Attention 블록.\n",
        "        # BiLSTM까지 끝난 데이터를 Attention에 먹여서 가중치를 학습\n",
        "        attention = layers.Attention()([x, x])\n",
        "        x = layers.Add()([x, attention])\n",
        "        x = layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        # faltten 으로 시퀀스 전체 백터화\n",
        "        # GlobalAveragePooling1D 때문에 2차원으로 변환되므로 Flatten이 의미를 잃음.\n",
        "        #x = layers.Flatten()(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        \n",
        "        # 분류기\n",
        "        # LSTM의 123차원을 비선형 변환으로 확장(512->256), BN/Dropout으로 일반화 성능 확보\n",
        "        x = layers.Dense(512, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "        \n",
        "        x = layers.Dense(256, activation='relu')(x)\n",
        "        # 나오는 학습률 결과에 따라 0.3 / 0.4 수준으로 한번 더 넣을지 결정\n",
        "        # 혹은 아예 LSTM 수준에서 조정을 하고 0.5 두번을 넣는 방안도 결과 보고 결정하자.\n",
        "        # x = layers.Dropout(0.5)(x) \n",
        "        \n",
        "        # 로짓을 클래스 수 만큼 만들어 softmax 확률을 출력\n",
        "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "        \n",
        "\n",
        "        # 모델 생성\n",
        "        self.model = keras.Model(inputs, outputs)\n",
        "        \n",
        "        # 컴파일\n",
        "        #clipnorm=1.0 == 그레디언트 폭주 방지(LSTM에서 사용하려면 꼭 해줘야 한다고 함)\n",
        "        # accuracy = 정답 정확도\n",
        "        # top_5_accuracy = 정답이 상위 5개 예측(확률) 안에 들어갔는지\n",
        "        loss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "        self.model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=cf.LEARNING_RATE, clipnorm=1.0),\n",
        "            loss=loss,\n",
        "            metrics=['accuracy', 'top_5_accuracy']\n",
        "        )\n",
        "        \n",
        "        print(\"모델 구성 완료!\")\n",
        "        return self.model\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"build_model 에러: {e}\")\n",
        "        raise\n",
        "\n",
        "# SignLanguageModel 클래스에 메서드 추가\n",
        "SignLanguageModel.build_model = build_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 시퀀스 길이 정규화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_sequence_length(self, sequence: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    시퀀스 길이를 고정 길이로 정규화\n",
        "    \n",
        "    Args:\n",
        "        sequence: 입력 시퀀스 (2D array)\n",
        "        \n",
        "    Returns:\n",
        "        정규화된 시퀀스 (SEQUENCE_LENGTH 길이)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 입력 검증\n",
        "        if sequence is None or sequence.size == 0:\n",
        "            raise ValueError(\"입력 시퀀스가 비어있습니다.\")\n",
        "        \n",
        "        if len(sequence.shape) != 2:\n",
        "            raise ValueError(f\"시퀀스는 2차원 배열이어야 합니다. 현재 shape: {sequence.shape}\")\n",
        "        \n",
        "        # NaN 값 처리\n",
        "        sequence = np.nan_to_num(sequence, copy=False).astype(np.float32)\n",
        "        \n",
        "        # 고정 길이로 정규화\n",
        "        seq = self.normalizer.pad_or_trim(sequence, cf.SEQUENCE_LENGTH)\n",
        "        \n",
        "        return seq\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"normalize_sequence_length 에러: {e}\")\n",
        "        raise\n",
        "\n",
        "# SignLanguageModel 클래스에 메서드 추가\n",
        "SignLanguageModel.normalize_sequence_length = normalize_sequence_length\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 데이터 로딩\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_processed_data(self, data_path):\n",
        "    \"\"\"\n",
        "    전처리된 landmark 데이터 로드\n",
        "    \n",
        "    Args:\n",
        "        data_path: 데이터 경로\n",
        "        \n",
        "    Returns:\n",
        "        X: 정규화된 시퀀스 데이터\n",
        "        y: 원-핫 인코딩된 라벨\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data_path = Path(data_path)\n",
        "        \n",
        "        # 경로 검증\n",
        "        if not data_path.exists():\n",
        "            raise FileNotFoundError(f\"데이터 경로가 존재하지 않습니다: {data_path}\")\n",
        "        \n",
        "        metadata_path = cf.DATA_ROOT / \"dataset_metadata.csv\"\n",
        "        if not metadata_path.exists():\n",
        "            raise FileNotFoundError(f\"메타데이터 파일이 존재하지 않습니다: {metadata_path}\")\n",
        "        \n",
        "        # 메타데이터 로드\n",
        "        metadata = pd.read_csv(metadata_path)\n",
        "        \n",
        "        if metadata.empty:\n",
        "            raise ValueError(\"메타데이터가 비어있습니다.\")\n",
        "        \n",
        "        # 컬럼 검증\n",
        "        required_columns = ['landmarks_file', 'word_gloss']\n",
        "        missing_columns = [col for col in required_columns if col not in metadata.columns]\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"메타데이터에 필요한 컬럼이 없습니다: {missing_columns}\")\n",
        "        \n",
        "        # 데이터 로딩\n",
        "        X, y = [], []\n",
        "        failed_files = []\n",
        "        \n",
        "        print(f\"총 {len(metadata)}개 파일 처리 중...\")\n",
        "        \n",
        "        for idx, row in metadata.iterrows():\n",
        "            try:\n",
        "                landmarks_file = data_path / row['landmarks_file']\n",
        "                if landmarks_file.exists():\n",
        "                    landmarks = np.load(landmarks_file)\n",
        "                    landmarks = self.normalize_sequence_length(landmarks)\n",
        "                    X.append(landmarks)\n",
        "                    y.append(row['word_gloss'])\n",
        "                else:\n",
        "                    failed_files.append(str(landmarks_file))\n",
        "                    print(f\"경고: 파일이 존재하지 않습니다: {landmarks_file}\")\n",
        "            except Exception as e:\n",
        "                failed_files.append(str(landmarks_file))\n",
        "                print(f\"경고: 파일 로딩 실패 {landmarks_file}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if len(X) == 0:\n",
        "            raise ValueError(\"로드된 데이터가 없습니다. 모든 파일 로딩에 실패했습니다.\")\n",
        "        \n",
        "        # 데이터 검증\n",
        "        sample_shape = X[0].shape\n",
        "        if sample_shape[1] != self.feature_dim:\n",
        "            raise ValueError(f\"특성 차원 불일치: 예상={self.feature_dim}, 실제={sample_shape[1]}\")\n",
        "        \n",
        "        if len(failed_files) > 0:\n",
        "            print(f\"총 {len(failed_files)}개 파일 로딩에 실패했습니다.\")\n",
        "        \n",
        "        print(f\"성공적으로 로드된 데이터: {len(X)}개\")\n",
        "        print(f\"데이터 형태: {np.array(X).shape}\")\n",
        "        \n",
        "        # 라벨 인코딩\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "        y_categorical = keras.utils.to_categorical(y_encoded, self.num_classes)\n",
        "        \n",
        "        return np.array(X), y_categorical\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"load_processed_data 에러: {e}\")\n",
        "        raise\n",
        "\n",
        "# SignLanguageModel 클래스에 메서드 추가\n",
        "SignLanguageModel.load_processed_data = load_processed_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(self, data_path, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    모델 학습\n",
        "    \n",
        "    Args:\n",
        "        data_path: 학습 데이터 경로\n",
        "        validation_split: 검증 데이터 비율\n",
        "        \n",
        "    Returns:\n",
        "        학습 히스토리\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 입력 검증\n",
        "        if not (0 < validation_split < 1):\n",
        "            raise ValueError(f\"validation_split은 0과 1 사이의 값이어야 합니다. 현재 값: {validation_split}\")\n",
        "        \n",
        "        print(\"=== 모델 학습 시작 ===\")\n",
        "        \n",
        "        # 데이터 로딩\n",
        "        print(\"데이터 로딩 중...\")\n",
        "        X, y = self.load_processed_data(data_path)\n",
        "        \n",
        "        if len(X) < 10:\n",
        "            raise ValueError(f\"학습 데이터가 너무 적습니다. 최소 10개 이상 필요합니다. 현재: {len(X)}개\")\n",
        "        \n",
        "        # 데이터 분할\n",
        "        print(\"데이터 분할 중...\")\n",
        "        try:\n",
        "            X_train, X_val, y_train, y_val = train_test_split(\n",
        "                X, y, test_size=validation_split, random_state=42, stratify=y.argmax(axis=1)\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            print(f\"stratify 실패, stratify 없이 분할: {e}\")\n",
        "            X_train, X_val, y_train, y_val = train_test_split(\n",
        "                X, y, test_size=validation_split, random_state=42\n",
        "            )\n",
        "        \n",
        "        print(f\"학습 데이터: {len(X_train)}개, 검증 데이터: {len(X_val)}개\")\n",
        "        \n",
        "        # 모델 구성\n",
        "        if self.model is None:\n",
        "            print(\"모델 구성 중...\")\n",
        "            self.build_model()\n",
        "        else:\n",
        "            print(\"기존 모델 사용\")\n",
        "        \n",
        "        # 모델 저장 경로 설정\n",
        "        model_save_path = cf.MODEL_SAVA_PATH\n",
        "        if not model_save_path.exists():\n",
        "            model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"모델 저장 경로 생성: {model_save_path}\")\n",
        "        \n",
        "        # 콜백 설정\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_accuracy', \n",
        "                patience=15, \n",
        "                restore_best_weights=True, \n",
        "                verbose=1\n",
        "            ),\n",
        "            keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss', \n",
        "                factor=0.5, \n",
        "                patience=7, \n",
        "                min_lr=1e-7, \n",
        "                verbose=1\n",
        "            ),\n",
        "            keras.callbacks.ModelCheckpoint(\n",
        "                model_save_path / \"best_model.h5\", \n",
        "                monitor='val_accuracy', \n",
        "                save_best_only=True, \n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "        \n",
        "        # Mixed Precision 설정 (GPU 메모리 최적화)\n",
        "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
        "        keras.mixed_precision.set_global_policy(policy)\n",
        "        print(\"Mixed Precision 활성화\")\n",
        "        \n",
        "        # 학습 실행\n",
        "        print(\"모델 학습 시작...\")\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=cf.EPOCHS,\n",
        "            batch_size=cf.BATCH_SIZE,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # 라벨 인코더 저장\n",
        "        print(\"라벨 인코더 저장 중...\")\n",
        "        with open(model_save_path / 'label_encoder.pkl', 'wb') as f:\n",
        "            pickle.dump(self.label_encoder, f)\n",
        "        \n",
        "        print(\"=== 학습 완료 ===\")\n",
        "        return history\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"train 에러: {e}\")\n",
        "        raise\n",
        "\n",
        "# SignLanguageModel 클래스에 메서드 추가\n",
        "SignLanguageModel.train = train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습 및 검증 함수\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"\n",
        "    학습/검증 Accuracy & Loss 시각화\n",
        "    \"\"\"\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(acc, label=\"Train Acc\")\n",
        "    plt.plot(val_acc, label=\"Val Acc\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(loss, label=\"Train Loss\")\n",
        "    plt.plot(val_loss, label=\"Val Loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습 관련된 전처리 필요 내용 - 내일 보고 수정 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UPPER_POSE_IDXS = [] # 상체 포즈\n",
        "FACE_IDXS = [] # 손 포즈즈\n",
        "# _norm_by_shoulders : 어깨 기준으로 중심점 잡는 코드. 수린이가 짠 코드로 대체하면 됨.\n",
        "\n",
        "def extract_upperbody_hands_features(rgb_img, hands, pose, face):\n",
        "    \"\"\"\n",
        "    상체(포즈 7점) + 좌/우 손(각 21점) + 얼굴 (25점) 사용해 (F,) 벡터 생성\n",
        "    F = 7*2 + 21*2 + 21*2 + 25 * 2= 148   \"\"\"\n",
        "    H, W, _ = rgb_img.shape\n",
        "    out = []\n",
        "\n",
        "    # -------- Pose (상체 점만) --------\n",
        "    res_pose = pose.process(rgb_img)\n",
        "    pose_xy = np.zeros((33, 2), dtype=np.float32)\n",
        "    has_pose = False\n",
        "    if res_pose.pose_landmarks:\n",
        "        has_pose = True\n",
        "        for i, lm in enumerate(res_pose.pose_landmarks.landmark):\n",
        "            pose_xy[i, 0] = lm.x\n",
        "            pose_xy[i, 1] = lm.y\n",
        "\n",
        "    # 어깨 기준 정규화 (어깨가 없으면 전체 0으로 둔다)\n",
        "    if has_pose:\n",
        "        left_sh = pose_xy[11]; right_sh = pose_xy[12]\n",
        "        pose_upper = pose_xy[UPPER_POSE_IDXS]           # (7,2)\n",
        "        pose_upper = _norm_by_shoulders(pose_upper, left_sh, right_sh)\n",
        "    else:\n",
        "        pose_upper = np.zeros((len(UPPER_POSE_IDXS), 2), dtype=np.float32)\n",
        "\n",
        "    out.append(pose_upper.flatten())  # 7*2 = 14\n",
        "\n",
        "    # -------- Face (subset) --------\n",
        "    res_face = face.process(rgb_img)\n",
        "    if res_face.multi_face_landmarks:\n",
        "        face_pts = np.array(\n",
        "            [(lm.x, lm.y) for i, lm in enumerate(res_face.multi_face_landmarks[0].landmark) if i in FACE_IDXS],\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        face_pts = _norm_by_shoulders(face_pts, left_sh, right_sh) if has_pose else face_pts\n",
        "    else:\n",
        "        face_pts = np.zeros((len(FACE_IDXS), 2), dtype=np.float32)\n",
        "    out.append(face_pts.flatten())  # ex) 25 * 2 = 50\n",
        "\n",
        "    # -------- Hands (좌/우 21점씩) --------\n",
        "    res_hands = hands.process(rgb_img)\n",
        "\n",
        "    lh = np.zeros((21, 2), dtype=np.float32)\n",
        "    rh = np.zeros((21, 2), dtype=np.float32)\n",
        "\n",
        "    if res_hands.multi_hand_landmarks and res_hands.multi_handedness:\n",
        "        # 정규화 좌표 기준점: 어깨 (가능하면), 아니면 이미지 중앙\n",
        "        if has_pose:\n",
        "            ref_l = pose_xy[11]; ref_r = pose_xy[12]\n",
        "        else:\n",
        "            # 포즈가 없으면 화면 가로 1.0 기준으로 임시 스케일/원점 설정\n",
        "            ref_l = np.array([0.5 - 0.1, 0.5], dtype=np.float32)\n",
        "            ref_r = np.array([0.5 + 0.1, 0.5], dtype=np.float32)\n",
        "\n",
        "        for lm, handedness in zip(res_hands.multi_hand_landmarks, res_hands.multi_handedness):\n",
        "            pts = np.array([(p.x, p.y) for p in lm.landmark], dtype=np.float32)  # (21,2)\n",
        "            pts = _norm_by_shoulders(pts, ref_l, ref_r)\n",
        "            label = handedness.classification[0].label  # 'Left' or 'Right'\n",
        "            if label.lower().startswith('left'):\n",
        "                lh = pts\n",
        "            else:\n",
        "                rh = pts\n",
        "\n",
        "    out.append(lh.flatten())  # 42\n",
        "    out.append(rh.flatten())  # 42\n",
        "\n",
        "    feat = np.concatenate(out, axis=0).astype(np.float32)  # (98,)\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 사용 예시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 얘 왜 내려가있음??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'SignLanguageModel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# SignLanguageModel 클래스에 메서드 추가\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[43mSignLanguageModel\u001b[49m\u001b[38;5;241m.\u001b[39mbuild_model \u001b[38;5;241m=\u001b[39m build_model\n",
            "\u001b[1;31mNameError\u001b[0m: name 'SignLanguageModel' is not defined"
          ]
        }
      ],
      "source": [
        "# def build_model(self):\n",
        "#     \"\"\"\n",
        "#     CNN + LSTM 하이브리드 모델 구성\n",
        "    \n",
        "#     구조:\n",
        "#     1. TimeDistributed CNN (프레임별 특징 추출)\n",
        "#     2. LSTM (시계열 패턴 학습)\n",
        "#     3. Dense (분류)\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # 입력 검증\n",
        "#         if self.sequence_length <= 0 or self.feature_dim <= 0:\n",
        "#             raise ValueError(f\"잘못된 입력 크기: sequence_length={self.sequence_length}, feature_dim={self.feature_dim}\")\n",
        "        \n",
        "#         print(\"모델 구성 중...\")\n",
        "        \n",
        "#         # 입력층\n",
        "#         inputs = keras.Input(shape=(self.sequence_length, self.feature_dim))\n",
        "        \n",
        "#         # CNN을 위한 reshape\n",
        "#         x = layers.Reshape((self.sequence_length, self.feature_dim, 1))(inputs)\n",
        "        \n",
        "#         # TimeDistributed CNN 블록 1\n",
        "#         x = layers.TimeDistributed(layers.Conv1D(64, 3, activation='relu', padding='same'))(x)\n",
        "#         x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "#         x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
        "#         x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "#         # TimeDistributed CNN 블록 2\n",
        "#         x = layers.TimeDistributed(layers.Conv1D(128, 3, activation='relu', padding='same'))(x)\n",
        "#         x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "#         x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
        "#         x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "#         # TimeDistributed CNN 블록 3\n",
        "#         x = layers.TimeDistributed(layers.Conv1D(256, 3, activation='relu', padding='same'))(x)\n",
        "#         x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "#         x = layers.TimeDistributed(layers.GlobalMaxPooling1D())(x)\n",
        "#         x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
        "        \n",
        "#         # LSTM 블록\n",
        "#         x = layers.LSTM(512, return_sequences=True, dropout=cf.DROPOUT_RATE)(x)\n",
        "#         x = layers.LSTM(256, return_sequences=True, dropout=cf.DROPOUT_RATE)(x)\n",
        "#         x = layers.LSTM(128, dropout=cf.DROPOUT_RATE)(x)\n",
        "        \n",
        "#         # 분류기\n",
        "#         x = layers.Dense(512, activation='relu')(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "#         x = layers.Dropout(0.5)(x)\n",
        "        \n",
        "#         x = layers.Dense(256, activation='relu')(x)\n",
        "#         x = layers.Dropout(0.5)(x)\n",
        "        \n",
        "#         outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "        \n",
        "#         # 모델 생성\n",
        "#         self.model = keras.Model(inputs, outputs)\n",
        "        \n",
        "#         # 컴파일\n",
        "#         self.model.compile(\n",
        "#             optimizer=keras.optimizers.Adam(learning_rate=cf.LEARNING_RATE, clipnorm=1.0),\n",
        "#             loss='categorical_crossentropy',\n",
        "#             metrics=['accuracy', 'top_5_accuracy']\n",
        "#         )\n",
        "        \n",
        "#         print(\"모델 구성 완료!\")\n",
        "#         return self.model\n",
        "        \n",
        "#     except Exception as e:\n",
        "#         print(f\"build_model 에러: {e}\")\n",
        "#         raise\n",
        "\n",
        "# # SignLanguageModel 클래스에 메서드 추가\n",
        "# SignLanguageModel.build_model = build_model\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
